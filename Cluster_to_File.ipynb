{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cluster_to_File(완료).ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Sug0qVAORjjz"},"source":["# ✅**Cluster_to_File(완료).ipynb - 클러스터링 결과 저장** \n","---\n","### 5만개의 Document를 K-means Clustering을 사용해 총 30개로 군집화\n","* 각 Document는 Cluster 별 Labeling 결과 저장 ('clustering_news.csv')\n","* 각 Cluster별 top_n_features 결과 저장 ('clustering_feature.csv')\n","\n","\n","> Used Method, Skills \n","* Data PreProcessing\n","* K-means Clustering"]},{"cell_type":"code","metadata":{"id":"qKn91pwAygoS"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import csv,re \n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgRlU0ObWspc"},"source":["# 불용어(Stop_word) \n","with open('/content/drive/MyDrive/DataMining TeamProject/stopword.txt', 'r') as f:\n","    STOP_WORDS = f.read().replace('\\n',' ').split()\n","\n","# Data Preprocessing\n","def preprocessing(sentence):\n","    sentence = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z]', ' ', sentence)\n","    # 불용어들이 제거되지 않아서 추가했습니다.\n","    temp = [word for word in sentence.split() if word not in STOP_WORDS]\n","    return ' '.join(temp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"erj3Em5yJrMb"},"source":["it = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/IT과학_202111.csv', encoding='euc-kr')\n","politics = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/정치_202111.csv', encoding='euc-kr')\n","world = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/세계_202111.csv', encoding='euc-kr')\n","culture = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/생활문화_202111.csv', encoding='euc-kr')\n","society = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/사회_202111.csv', encoding='euc-kr')\n","economy = pd.read_csv('/content/drive/MyDrive/DataMining TeamProject/NewsData/경제_202111.csv', encoding='euc-kr')\n","\n","it = it.iloc[:,[2,3]]\n","it.columns = ['title', 'content']\n","politics = politics.iloc[:, [2,3]]\n","politics.columns = ['title', 'content']\n","world = world.iloc[:,[2,3]]\n","world.columns = ['title', 'content']\n","culture = culture.iloc[:,[2,3]]\n","culture.columns = ['title', 'content']\n","society = society.iloc[:, [2,3]]\n","society.columns = ['title', 'content']\n","economy = economy.iloc[:, [2,3]]\n","economy.columns = ['title', 'content']\n","\n","news = pd.concat([it,politics,world,culture,society,economy], ignore_index=True)\n","news['content_cleand'] = news['content'].apply(preprocessing)\n","content = news['content_cleand'].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTjUImUXPN1C"},"source":["# K-means Clustering\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.preprocessing import normalize\n","from sklearn.cluster import KMeans\n","\n","n_clusters = 100\n","\n","vectorizer = TfidfVectorizer(stop_words=STOP_WORDS)\n","X = vectorizer.fit_transform(content)\n","\n","X = normalize(X)\n","\n","kmeans = KMeans(n_clusters=n_clusters).fit(X)\n","\n","labels = kmeans.labels_\n","centers = kmeans.cluster_centers_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDYlZb3fUdb8"},"source":["# Cluster 별 뉴스 저장 ('clustering_news.csv')\n","news['labels'] = labels\n","news.to_csv('/content/drive/MyDrive/DataMining TeamProject/clustering_news.csv', encoding='euc-kr')\n","print(kmeans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxuEYZwibMek"},"source":["# Cluster 내부의 데이터에서 핵심 단어 10개 추출\n","def get_cluster_details(cluster_model, cluster_data, feature_names,\n","                       cluster_num, top_n_features=10):\n","    cluster_details = {}\n","    center_feature_idx = cluster_model.cluster_centers_.argsort()[:,::-1]\n","    \n","    for cluster_num in range(cluster_num):\n","        cluster_details[cluster_num] = {}\n","        cluster_details[cluster_num]['cluster'] = cluster_num\n","        \n","        top_ftr_idx = center_feature_idx[cluster_num, :top_n_features]\n","        top_ftr = [feature_names[idx] for idx in top_ftr_idx]\n","        top_ftr_val = cluster_model.cluster_centers_[cluster_num, top_ftr_idx].tolist()\n","        \n","        cluster_details[cluster_num]['top_features'] = top_ftr\n","        cluster_details[cluster_num]['top_featrues_value'] = top_ftr_val\n","        filenames = cluster_data[cluster_data['labels']==cluster_num]['title']\n","        filenames = filenames.values.tolist()\n","        cluster_details[cluster_num]['filenames'] = filenames\n","    \n","    return cluster_details\n","\n","clustering_feature = []\n","def save_cluster_details(cluster_details):\n","    for cluster_num, cluster_detail in cluster_details.items():\n","        clustering_feature.append(cluster_detail['top_features'])\n","\n","feature_names = vectorizer.get_feature_names()\n","cluster_details = get_cluster_details(cluster_model=kmeans,\n","                                      cluster_data=news,\n","                                      feature_names=feature_names,\n","                                      cluster_num=100,\n","                                      top_n_features=20)\n","save_cluster_details(cluster_details)\n","print(clustering_feature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2ZssCGTe8zb"},"source":["# Cluster 별 상위 feature 저장 ('clustering_features.csv')\n","with open('/content/drive/MyDrive/DataMining TeamProject/clustering_feature.csv', 'w', encoding='euc-kr', newline='') as f:\n","    write = csv.writer(f)\n","    for row in enumerate(clustering_feature):\n","        write.writerow(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss21iazt4Q6W"},"source":[""],"execution_count":null,"outputs":[]}]}